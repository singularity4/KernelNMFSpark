{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make it Python2 & Python3 compatible\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "if sys.version[0] == 3:\n",
    "    xrange = range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook deployment includes Spark automatically within each Python notebook kernel. This means that, upon kernel instantiation, there is an SparkContext object called sc immediatelly available in the Notebook, as in a PySpark shell. Let's take a look at it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "# Spark version we are using\n",
    "print( sc.version )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Linear algebra librarires from ML lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Matrices\n",
    "from pyspark.mllib.linalg.distributed import BlockMatrix\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from file system or create tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:475\n"
     ]
    }
   ],
   "source": [
    "# Xrdd = sc.textFile(\"data.txt\")\n",
    "Xrdd = sc.parallelize([IndexedRow(0, [1, 1, 0]), IndexedRow(1, [1, 0, 0]),\n",
    "                              IndexedRow(2, [1, 1, 0]), IndexedRow(3, [0, 0, 1])])\n",
    "print(Xrdd)\n",
    "#This data is now RDD structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a distributed block matrix from input data. \n",
    "Different types of matrices, will be denoted with different suffixes\n",
    "#X_bm : block matrix distributed rdd\n",
    "#X_np : numpy local matrix\n",
    "#X_rm : indexed row matrix\n",
    "#X_local: local matrix MLlib structure\n",
    "see: https://spark.apache.org/docs/latest/mllib-data-types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 1.,  1.,  0.],\n",
      "             [ 1.,  0.,  0.],\n",
      "             [ 1.,  1.,  0.],\n",
      "             [ 0.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "#converte RDD to IndexedRowMatrix\n",
    "X_rm = IndexedRowMatrix(Xrdd)\n",
    "#convert IndexedRowMatrix to Block distributed matrix\n",
    "\n",
    "#define number of blocks for distributed matrix for each variable\n",
    "nNumberPerBlock=3 \n",
    "mNumberPerBlock=2\n",
    "kNumberPerBlock=3\n",
    "X_bm = X_rm.toBlockMatrix(mNumberPerBlock, nNumberPerBlock)\n",
    "print(X_bm.toLocalMatrix())\n",
    "X_bm.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are solving the following optimization problem \\Phi(X) = \\Phi(X) F H.\n",
    "For start \\Phi(X)=X.\n",
    "We create two random matrices F and H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 0.14933398,  0.40924514,  0.07532505],\n",
      "             [ 0.47027156,  0.4806673 ,  0.6953724 ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#matrix H : kxn\n",
    "#number of bases for factorization\n",
    "k = 2; \n",
    "n = X_bm.numCols()\n",
    "m = X_bm.numRows()\n",
    "\n",
    "Hindexedrows = []\n",
    "for i in range(0,k):\n",
    "\tHindexedrows.append((i, np.random.random_sample((n,))))\n",
    "\n",
    "# Hindexedrows is a num py object -> we create RDD from him\n",
    "H_rdd = sc.parallelize(Hindexedrows)\n",
    "# Then we create IndexedRowMatrix , which is a distributed matrix object and create a block matrix\n",
    "H_bm = IndexedRowMatrix(H_rdd).toBlockMatrix(kNumberPerBlock, nNumberPerBlock)\n",
    "H_bm.validate()\n",
    "H_local = H_bm.toLocalMatrix()\n",
    "\n",
    "print(H_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 0.79258059,  0.77966523],\n",
      "             [ 0.75551724,  0.0253088 ],\n",
      "             [ 0.46144306,  0.22886885]])\n"
     ]
    }
   ],
   "source": [
    "#matrix F : nxk\n",
    "Findexedrows = []\n",
    "for i in range(0,n):\n",
    "\tFindexedrows.append((i, np.random.random_sample((k,))))\n",
    "\n",
    "F_bm = IndexedRowMatrix(sc.parallelize(Findexedrows)).toBlockMatrix(nNumberPerBlock, kNumberPerBlock)\n",
    "F_bm.validate()\n",
    "\n",
    "print(F_bm.toLocalMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Kernel matrix -> this matrix is the largest. All multiplications with this matrix are done with blockmatrix mulitplication function.\n",
    "All other multiplactions can be done locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 3.,  2.,  0.],\n",
      "             [ 2.,  2.,  0.],\n",
      "             [ 0.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "K = X_bm.transpose().multiply(X_bm)\n",
    "K.validate()\n",
    "print(K.toLocalMatrix())\n",
    "# faster:  IndexedRowMatrixobject.computeGramianMatrix() -> then create block matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "mu = 100\n",
    "num_iter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................... Finished \n"
     ]
    }
   ],
   "source": [
    "# block_matrix.toLocalMatrix() converts for local rdd matrix\n",
    "# local_matrix.toArray() converts to numpy matrix\n",
    "# some matrix operations are not available for distributed objects\n",
    "# we run large matrix multiplicaiton with K with distributed matrix operation\n",
    "# operations on nxk matrices are done locally with numpy\n",
    "\n",
    "for i in range(0,num_iter):\n",
    "    #-----update for H -------- H= H.* A./B\n",
    "    \n",
    "    # multiplicaiton with K (largematrix)\n",
    "    FK_bm = F_bm.transpose().multiply(K)\n",
    "\n",
    "    # A = nominator for update rule\n",
    "    A_np = np.add( alpha * FK_bm.toLocalMatrix().toArray()  ,2*mu*H_local.toArray())\n",
    "    \n",
    "    # denominator FË†t*K*F*H\n",
    "    FKFH_bm = FK_bm.multiply(F_bm).multiply(H_bm)\n",
    "    # denominator H*H^T*H\n",
    "    HHH_np = np.matmul(np.matmul(H_local.toArray(), H_local.toArray().transpose()), H_local.toArray())\n",
    "    # denominator whole\n",
    "    B_np = np.add( alpha*FKFH_bm.toLocalMatrix().toArray(), 2*mu*HHH_np)\n",
    "    \n",
    "    #update rule for H \n",
    "    H_np = np.multiply( np.divide(A_np, B_np), H_local.toArray())\n",
    "    \n",
    "    # convert numpy H object first to IndexedRowMatrix and then to blockmatrix \n",
    "    H_bm = IndexedRowMatrix(sc.parallelize( list(enumerate(H_np.tolist()) ))).toBlockMatrix(kNumberPerBlock, nNumberPerBlock)\n",
    "    # convet also to local matrix, used in each iteration for numpy operations\n",
    "    H_local = H_bm.toLocalMatrix()\n",
    "    \n",
    "    #----------update for F-------\n",
    "    # nominator K*H^T\n",
    "    KH_bm = K.multiply( H_bm.transpose() )\n",
    "    # denominator: K*F*H*H^T\n",
    "    KFHH_bm = K.multiply(F_bm).multiply(H_bm).multiply(H_bm.transpose())\n",
    "    # udpate rule for F\n",
    "    F_np = np.multiply( F_bm.toLocalMatrix().toArray() , np.divide( KH_bm.toLocalMatrix().toArray(), KFHH_bm.toLocalMatrix().toArray() ))\n",
    "    # convert numpy F object to to IndexedRowMatrix and then to blockmatrix \n",
    "    F_bm = IndexedRowMatrix(sc.parallelize( list(enumerate(F_np.tolist()) ))).toBlockMatrix(nNumberPerBlock, kNumberPerBlock)\n",
    "    \n",
    "    print('.', end='')\n",
    "\n",
    "print(' Finished ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00526809e+00   9.99752422e-01   9.92589794e-29]\n",
      " [  9.89292777e-01   2.21286704e-02   9.76815963e-29]\n",
      " [  1.00526809e+00   9.99752422e-01   9.92589794e-29]\n",
      " [  9.87388149e-29   0.00000000e+00   9.74935356e-57]]\n"
     ]
    }
   ],
   "source": [
    "#recommendations Y= X*F*H\n",
    "Y = np.matmul(X_bm.toLocalMatrix().toArray() , np.matmul(F_np, H_np))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 1.,  1.,  0.],\n",
      "             [ 1.,  0.,  0.],\n",
      "             [ 1.,  1.,  0.],\n",
      "             [ 0.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "#print original data\n",
    "print(X_bm.toLocalMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark (Py 2)",
   "language": "",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
